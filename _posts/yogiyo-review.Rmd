---
output:
  html_document:
    highlight: tango
    keep_md: yes
    theme: spacelab
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

</br>

***

<center>
## "요기요 음식리뷰를 통한 가성비 음식점 찾아내기"
*WooJun Kang*
</center>

***

<center>
### **오늘 뭐 먹지?**
</center>

배달 앱을 키며 유저들이 하는 생각입니다.
어떤 음식을 배달시킬 지 각자의 기준이 있을 것입니다.
우선 치킨을 먹을지 피자를 먹을지 정하고, 어떤 치킨을 먹을지 정합니다.
여기서 음식점 선택의 공통적 기준은 '맛' 입니다. 하지만 돈이 많지 않는 대학생들에게는 맛도 맛이지만 얼마냐 양이 많은지도 중요할 것입니다.

돈이 없는 학생에게 배달 음식 결정에서 주된 선택기준은 
저렴하고 양이 많은 음식입니다.
하지만 기존 배달앱에 정렬 방식에는 '최소 주문 금액순' 정도입니다.

따라서 음식점 리뷰를 통해 가성비가 좋은 음식점을 가려냄으로써
'가성비 순'이란 새로운 필터 방식을 제안합니다.


***

</br>

> #### Load Library

사용할 라이브러리를 불러옵니다.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(httr)
library(jsonlite)
library(rvest)
library(urltools)
library(NLP4kec)
library(tm)
library(RWeka)
```

</br>

***

</br>

> ### **1. 리뷰 수집**

수집대상: 9개의 기존 카테고리 안에서 '리뷰가 많은 순'으로 상위 10개의 가게 리뷰 수집
`1인분 주문`, `야식`, `프랜차이즈`는 겹치는 가게가 많아 수집대상에서 제외했습니다.

수집하는 9개의 카테고리는 아래와 같습니다.
`치킨`, `피자/양식`, `중국집`, `한식`, `일식/돈까스`, `족발/보쌈`, `야식`, `분식`, `카페/디저트`

주소는 연세대(서울특별시 서대문구 연세로 50) 기준.

</br>

> #### *1-1. 가게 정보 수집*

개별 가게 페이지로 이동 후 리뷰를 수집하기 위해, 먼저 요기요 측에서 부여한 `가게 고유 번호`를 크롤링해와야 합니다. 
```{r message=FALSE, warning=FALSE}
category <- c('치킨', '피자양식', '중식', '한식', '일식돈까스', '족발보쌈', '분식', '카페디저트')
store_info <- data.frame()

## 음식 카테고리, 가게 교유 ID, 가게 이름, 배달비, 최소 주문 금액, 총 리뷰 수를 크롤링 합니다.
for(i in 1:length(category)){
  
  # cat('카테고리 [', category[i], '] 가게 고유 번호 수집중...\n')
  
  # 리뷰 많은 순으로 정렬했을때 상위 20곳의 음식점에 대한 정보 http 요청
  res <- GET(url = 'https://www.yogiyo.co.kr/api/v1/restaurants-geo/',
             query = list(category = category[i] %>% url_encode() %>% toupper() %>% I(),
                          items = 20,
                          lat = 37.5565050755347,
                          lng = 126.939656244325,
                          order = 'review_count',
                          page = 0),
             add_headers('X-ApiSecret' = 'fe5183cc3dea12bd0ce299cf110a75a2',
                         'X-ApiKey' = 'iphoneap'))
  
  # cat('[', category[i], '] http 요청 상태 코드:', res$status_code, '\n')
  
  
  # JSON형태로 가게 정보 추출
  temp <- res %>% httr::content(as = 'text', encoding = 'UTF-8') %>% fromJSON()
  
  # 카테고리별 가게 정보 하나의 데이터 프레임으로  
  store <- data.frame(category = category[i], # 카테고리
                      id = temp$restaurants$id, # 가게 ID
                      name = temp$restaurants$name, # 가게 이름
                      delivery_fee = temp$restaurants$delivery_fee, # 배달비
                      min_order_amount = temp$restaurants$min_order_amount, # 최소주문금액
                      review_count = temp$restaurants$review_count, # 총 리뷰 수
                      stringsAsFactors = FALSE) 
  
  # 전체 카테고리 하나의 데이터 프레임으로 
  store_info <- rbind(store_info, store, stringsAsFactors = FALSE)
  
  Sys.sleep(5)

}

```

</br>
카테고리가 중복되는 음식점은 하나의 카테고리만 갖게 합니다.

```{r message=FALSE, warning=FALSE}
n_distinct(store_info$id) 
store_info <- store_info[!duplicated(x = store_info$id), ]
nrow(store_info)
```

</br>
`리뷰 수`가 너무 적으면 분석의 정확도가 떨어질 수 있어, `리뷰 수`가 100개가 안되는 음식점은 제외시켰습니다.

```{r message=FALSE, warning=FALSE}
summary(store_info$review_count)
store_info <- store_info %>% filter(review_count >= 100)
```

</br>
최종 음식점 정보 데이터 셋

```{r}
str(store_info)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
cat('최종 분석할 음식점의 수는', nrow(store_info), '입니다.')
```

</br>

> #### *1-2. 음식점 리뷰 수집 *

`for loop`를 돌리기 위해 최대 리뷰 수를 10으로 나눠 `리뷰 최대 페이지`를 알아냅니다.

```{r message=FALSE, warning=FALSE}
max_review_page <- (store_info$review_count / 10) %>% ceiling()
```

```{r message=FALSE, warning=FALSE}
# 빈 데이터 프레임 
store_review <- data.frame()

for (i in 1:nrow(store_info)) {
  
  # cat('##### [', i, '/', nrow(store_info), '] 음식점 리뷰 수집 시작! #####\n')
  
  # 음식점 리뷰 페이지 url 할당
  url <- str_c('https://www.yogiyo.co.kr/api/v1/reviews/', store_info$id[i], sep = '')
  # 리뷰 페이지 수
  n <- max_review_page[i]
  
  for (j in 1:n) {
    
    #  cat('[', store_info$name[i], '] 리뷰 수집 중...(', j, '/', n, ')\n')
    
    # http 요청
    res <- GET(url = url,
               query = list(count = 10,
                            only_photo_review = 'false',
                            page = j,
                            sort = 'time'))
    
    # cat('http 요청 상태 코드:', res$status_code, '\n')
    
    # JSON 형태로 가게 리뷰 추출
    temp_review <- res %>% httr::content(as = 'text', encoding = 'UTF-8') %>% fromJSON()
    
    # 필요한 정보만 가져와 하나의 데이터 프레임으로
    reviews <- data.frame(id = store_info$id[i],
                          name = store_info$name[i], 
                          comment = temp_review$comment, # 음식점 리뷰
                          rating_quantity = temp_review$rating_quantity, # 양 평점
                          stringsAsFactors = FALSE)
    
    # 모든 리뷰 하나의 데이터 프레임으로
    store_review <- rbind(store_review, reviews, stringsAsFactors = FALSE)
    
  }
}
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
cat('분석할 음식점의 리뷰 수는', nrow(store_review), '입니다.')
```

</br>

***

</br>

> ### **2. 리뷰 분석**

</br>

> #### *2-1. '가성비 있는 음식점'이란 의미를 내포하는 리뷰 추출*

'가성비가 좋다'라는 의미를 직접적으로 내포하는 리뷰와
'양이 많다'는 의미를 내포하는 리뷰를 
가성비 있는 음식점의 리뷰라 가정했습니다.
 
따라서 '가성비'란 단어를 포함한 리뷰와
'양'과 '많'이란 단어를 포함한 리뷰만 추출했습니다.

또한 가성비가 좋다는 말인 '혜자'라는 단어 포함한 것도
가성비와 관련된다 판단했습니다.

```{R message=FALSE, warning=FALSE}
# '양'이란 단어와 '많'이란 단어가 포함된 리뷰만 추출
store_quantity <- store_review %>% 
  filter(str_detect(.$comment, '양') & str_detect(.$comment, '많')) 

# '가성비'란 단어가 포함된 리뷰만 추출
store_co_ef <- store_review %>% 
  filter(str_detect(.$comment, '가성비'))

# '혜자'란 단어가 포함된 리뷰만 추출
store_haeja <- store_review %>% 
  filter(str_detect(.$comment, '혜자'))

# 데이터 프레임을 합치고 중복되는 리뷰를 제거합니다.
total_cost_ef <- store_quantity %>% 
  rbind(store_co_ef, 
        stringsAsFactors = FALSE) %>% 
  rbind(store_haeja,
        stringsAsFactors = FALSE) %>%
  `[`(!duplicated(.$comment), )
```

</br>
단순하게 단어의 포함 여부만으로 리뷰를 가려내다보니깐
*'가성비가 뛰어나지 않다'*, *'양이 많은건 아니다'*, *'양이 조금만 더 많았으면'*과 같은 
`부정적인 리뷰`도 추출됐습니다.

```{r message=FALSE, warning=FALSE}
head(total_cost_ef$comment)
tail(total_cost_ef$comment)
```

</br>

> #### *2-2. 텍스트 마이닝*

</br>

> ##### 2-2-1. 형태소 분석

형태소 분석은 `은전한닢 프로젝트`로 개발된 형태소 분석 패키지인 `NLP4kec`를 이용해 진행했습니다.
comment 컬럼의 공백을 모두 제거합니다.
`은전한닢` 형태소 분석기는 띄어쓰기 를 자체적으로 구분합니다.

```{r message=FALSE, warning=FALSE}
total_cost_ef$comment <- total_cost_ef$comment %>% str_remove_all(pattern = '\\s+')
```

</br>
형태소를 분석하여 객체에 할당합니다.

```{r message=FALSE, warning=FALSE}
total_parsed <- r_parser_r(contentVector = total_cost_ef$comment, language = 'ko')
```

</br>
형태소 분석 전 리뷰와 분석 후 리뷰를 출력해봅니다.

```{r message=FALSE, warning=FALSE}
total_cost_ef$comment[1]
total_parsed[1]
```

</br>
'양이 작다'와 같은 가성비 의미에 반대되는 텍스트 추출하기 위해
인접한 2개의 단어렬 결합한 `bigram`을 생성합니다.

`말뭉치` 생성을 위해 형태소 분석된 문자 벡터를 벡터 소스로 변경해야 합니다.
벡터 소스는 벡터의 개별 원소를 각각의 문서로 인식합니다.

```{r message=FALSE, warning=FALSE}
total_corpus <- total_parsed %>% VectorSource() %>% VCorpus()
```

</br>
제대로 생성됐는지 확인해봅니다.

```{r message=FALSE, warning=FALSE}
identical(x = nrow(total_cost_ef),
          y = length(total_corpus))
```

</br>
생성된 말뭉치는 `content`와 `meta`라는 2개의 원소를 갖는 리스트입니다.

```{r message=FALSE, warning=FALSE}
total_corpus[[1]]$content
total_corpus[[1]]$meta 
```

</br>

> ##### 2-2-2. 사전생성

`bigram` 생성을 위해 사용자함수를 만듭니다.
`min`과 `max`에 할당할 숫자를 바꾸면 원하는 N-gram을 만들 수 있습니다.

```{r message=FALSE, warning=FALSE}
bigram <- function(x, min = 2, max = 2){
  NGramTokenizer(x = x, control = Weka_control(min = min, max = max))
}

# bigram으로 DTM 생성
bigramList <- total_corpus %>% 
  TermDocumentMatrix(control = list(tokenize = bigram)) %>% 
  apply(MARGIN = 1, FUN = sum) %>% 
  sort(decreasing = TRUE)
```

```{r message=FALSE, warning=FALSE}
head(bigramList)
tail(bigramList)
```

</br>
사전 제작을 위해 bigramList를 txt파일로 내보냅니다.

```{r message=FALSE, warning=FALSE}
write.table(x = names(bigramList),
            quote = FALSE,
            file = './data/yogiyo_for_dic.txt',
            row.names = FALSE,
            col.names = FALSE)
```

</br>
노가다(?)로 '가성비'에 반대되는 의미를 갖는 것만 남깁니다.

```{r message=FALSE, warning=FALSE}
neg_dic <- readLines(file('./data/yogiyo_neg_dic.txt'))
```

</br>
`가성비 반대 사전`을 출력해봅니다.

```{r message=FALSE, warning=FALSE}
head(neg_dic)
tail(neg_dic)
```

</br>
`가성비 반대 사전`에 있는 bigram을 포함하고 있으면 가성비가 없다고 평가한 리뷰로 간주했습니다.

```{r message=FALSE, warning=FALSE}
total_neg_coef <- data.frame()
for (i in 1:length(total_parsed)) {
  
  # 형태소 중 '가성비 반대 사전'에 있는 bigram갯수 할당
  neg_coef <- total_parsed[i] %>% 
    str_detect(pattern = neg_dic) %>% 
    sum()
  
  total_neg_coef <- rbind(total_neg_coef, neg_coef, stringsAsFactors = FALSE)
  
}

total_cost_ef$cost_efficiency <- ifelse(total_neg_coef == 0, 1, 0) %>% as.vector()
```

</br>
가성비 없다고 한 리뷰를 일부 출력해 봅니다.
```{r message=FALSE, warning=FALSE}
total_cost_ef %>% 
  filter(cost_efficiency == 0) %>% 
  select(comment) %>% 
  sample_n(5)
```

</br>
`가성비 순`으로 정렬하기 위해 해당 음식점 리뷰 중 가성비가 좋다고 한 리뷰 갯수 파악합니다.

```{r message=FALSE, warning=FALSE}
num_cost_ef <- total_cost_ef %>% 
  group_by(id) %>% 
  summarise(num_cost_ef = sum(cost_efficiency)) 

total <- left_join(x = store_info,
                   y = num_cost_ef,
                   by = 'id')
```

```{r message=FALSE, warning=FALSE}
str(total)
```

</br>
가성비 리뷰 개수를 전체 리뷰 개수로 나누어 `가성비 리뷰 비율` 계산합니다.

```{r message=FALSE, warning=FALSE}
total$ratio_cost_ef <-total$num_cost_ef / total$review_count
```

</br>
`가싱비 리뷰 비율 높은 순`으로 출력해 봅니다.

```{r echo=FALSE, message=FALSE, warning=FALSE}
cat('## 연세대 인근 가성비 좋은 음식점 상위 10곳 입니다 ##\n', 
    '1 :', arrange(total, desc(ratio_cost_ef))[1, 3], '\n',
    '2 :', arrange(total, desc(ratio_cost_ef))[2, 3], '\n',
    '3 :', arrange(total, desc(ratio_cost_ef))[3, 3], '\n',
    '4 :', arrange(total, desc(ratio_cost_ef))[4, 3], '\n',
    '5 :', arrange(total, desc(ratio_cost_ef))[5, 3], '\n',
    '6 :', arrange(total, desc(ratio_cost_ef))[6, 3], '\n',
    '7 :', arrange(total, desc(ratio_cost_ef))[7, 3], '\n',
    '8 :', arrange(total, desc(ratio_cost_ef))[8, 3], '\n',
    '9 :', arrange(total, desc(ratio_cost_ef))[9, 3], '\n',
    '10:', arrange(total, desc(ratio_cost_ef))[10, 3], '\n')
```

</br>
한식 음식점 `가성비 높은 순`으로 출력합니다.

```{r echo=FALSE, message=FALSE, warning=FALSE}
cat('## 연세대 인근 가성비 좋은 음식점(한식) 상위 10곳 입니다 ##\n', 
    '1 :', arrange(total %>% filter(category == '한식'), desc(ratio_cost_ef))[1, 3], '\n',
    '2 :', arrange(total %>% filter(category == '한식'), desc(ratio_cost_ef))[2, 3], '\n',
    '3 :', arrange(total %>% filter(category == '한식'), desc(ratio_cost_ef))[3, 3], '\n',
    '4 :', arrange(total %>% filter(category == '한식'), desc(ratio_cost_ef))[4, 3], '\n',
    '5 :', arrange(total %>% filter(category == '한식'), desc(ratio_cost_ef))[5, 3], '\n',
    '6 :', arrange(total %>% filter(category == '한식'), desc(ratio_cost_ef))[6, 3], '\n',
    '7 :', arrange(total %>% filter(category == '한식'), desc(ratio_cost_ef))[7, 3], '\n',
    '8 :', arrange(total %>% filter(category == '한식'), desc(ratio_cost_ef))[8, 3], '\n',
    '9 :', arrange(total %>% filter(category == '한식'), desc(ratio_cost_ef))[9, 3], '\n',
    '10:', arrange(total %>% filter(category == '한식'), desc(ratio_cost_ef))[10, 3], '\n')
```

</br>

***

</br>

> #### **3. 한계점**

1) 우선 가성비를 양이 많다는 것으로 단순하게 정의했다. 실제로 가성비를 좀 더 명확하게 정의 할 필요가 있다.
2) 배달비나 최소주문금액 등 가격에 미치는 다른 요소는 고려하지 않았다.
3) 가성비 관련 사전을 생성할 때도 부정, 중립, 긍정과 같이 총 3가지 정도의 사전을 제작해 감성 분석을 한다면, 긍정적 혹은 부정적 입장인지 파악할 때 더 정확했을 것이다.

</br>
</br>
</br>
</br>
</br>
